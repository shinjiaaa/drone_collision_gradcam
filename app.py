from fastapi import FastAPI, Response, Request, UploadFile, File
from fastapi.responses import HTMLResponse, StreamingResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
import uvicorn
import asyncio
import cv2
import time
import numpy as np
import os

# ëª¨ë“ˆ ì„í¬íŠ¸
from cam import UniversalCamera as Camera 
from model import CollisionModel
from llm_integration import describe_heatmap
from utils import bgr_to_jpeg_bytes, jpeg_bytes_to_base64

try:
    from risk_refiner import RiskRefiner
    risk_refiner = RiskRefiner()
except ImportError:
    risk_refiner = None

app = FastAPI()

# ì „ì—­ ë³€ìˆ˜ ì„¤ì •
current_realtime_prob = 0.0  # ì‹¤ì‹œê°„ ëª¨ë¸ í™•ë¥  ì €ì¥ìš©
latest_description = {"text": "ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...", "prob_percent": 0, "ts": 0}

# Static ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
static_dir = os.path.join(current_dir, "static")
if not os.path.exists(static_dir):
    os.makedirs(static_dir)

app.mount("/static", StaticFiles(directory=static_dir), name="static")

FRAME_WIDTH = 640

# ì¹´ë©”ë¼ ë° ëª¨ë¸ ì´ˆê¸°í™”
camera = Camera(mode="zed", source=0, width=FRAME_WIDTH, height=480)
model = CollisionModel("rebuilt_model.h5", input_size=(128, 128))
camera.set_model(model)

@app.get("/", response_class=HTMLResponse)
async def index():
    template_path = os.path.join(current_dir, "templates", "index.html")
    try:
        with open(template_path, "r", encoding="utf-8") as f:
            return HTMLResponse(f.read())
    except FileNotFoundError:
        return HTMLResponse("<h2>templates/index.html íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.</h2>")

def gen_frames():
    """ì‹¤ì‹œê°„ ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë° ë° í™•ë¥  ì „ì—­ ë³€ìˆ˜ ì—…ë°ì´íŠ¸"""
    global current_realtime_prob
    while True:
        res = camera.read_pred()
        if res is None:
            frame = camera.read()
            if frame is None:
                time.sleep(0.01)
                continue
            display_frame = frame
        else:
            display_frame, label, info = res
            current_realtime_prob = info.get('prob', 0)

        ret, jpeg = cv2.imencode(".jpg", display_frame)
        if not ret:
            continue

        yield (
            b"--frame\r\n"
            b"Content-Type: image/jpeg\r\n\r\n" + jpeg.tobytes() + b"\r\n"
        )

@app.get("/video_feed")
def video_feed():
    return StreamingResponse(
        gen_frames(), media_type="multipart/x-mixed-replace; boundary=frame"
    )

@app.get("/latest_description")
async def get_description():
    return JSONResponse(latest_description)
# app.py ë‚´ì˜ analyze_upload í•¨ìˆ˜ ìˆ˜ì •
@app.post("/analyze_upload")
async def analyze_upload(file: UploadFile = File(...)):
    data = await file.read()
    nparr = np.frombuffer(data, np.uint8)
    bgr = cv2.imdecode(nparr, cv2.IMREAD_COLOR)

    if bgr is None:
        return {"error": "ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨"}

    # 1. ëª¨ë¸ ë¶„ì„ ì‹¤í–‰
    overlay_bgr, label, heatmap_meta = model.predict_and_gradcam(bgr)

    # 2. [í•µì‹¬] ìˆ˜ì¹˜ ì¦í­/ë³´ì • ë¡œì§ì„ LLM í˜¸ì¶œ ì „ì— ë¨¼ì € ì‹¤í–‰
    raw = heatmap_meta.get('prob', 0)
    if raw <= 0.001: final_val = 0
    elif 0.001 < raw <= 0.02: final_val = 30 + (raw * 1000) 
    elif 0.02 < raw <= 0.1: final_val = 60 + (raw * 100)
    else: final_val = 85 + (raw * 10)
    
    prob_percent = int(min(final_val, 99)) # í™”ë©´ì— í‘œì‹œë  94% ê°™ì€ ìˆ˜ì¹˜

    try:
        # 3. [ì¤‘ìš”] ë³´ì •ëœ prob_percentë¥¼ LLMì— ì „ë‹¬!!
        result = await describe_heatmap(
            label, 
            heatmap_meta, 
            FRAME_WIDTH, 
            calibrated_prob=prob_percent  # <--- ì´ ë¶€ë¶„ì„ ë°˜ë“œì‹œ ë„£ì–´ì•¼ í•¨!
        )
        llm_text = result["text"]
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ LLM ì˜¤ë¥˜: {e}")
        llm_text = f"{label} ê°ì§€ë¨ (ë¶„ì„ ì˜¤ë¥˜)"

    jpeg_bytes = bgr_to_jpeg_bytes(overlay_bgr)
    b64 = jpeg_bytes_to_base64(jpeg_bytes)

    return {
        "image": b64,
        "text": llm_text,           # ì´ì œ LLMì´ 94%ë¥¼ ì¸ì§€í•œ ë‹µë³€ì„ ë³´ëƒ„
        "prob_percent": prob_percent, # UI í•˜ë‹¨ì— í‘œì‹œë  ìˆ˜ì¹˜
    }

async def llm_worker():
    global latest_description, current_realtime_prob
    print("ğŸš€ LLM Worker ì‹œì‘ë¨ (ì´ˆê°•ë ¥ ëª¨ë“œ)")
    
    while True:
        res = camera.read_pred()
        if res is None:
            await asyncio.sleep(0.5)
            continue

        _, label, info = res 

        # app.py ì˜ llm_worker ë‚´ë¶€
        try:
            # 1. ë¨¼ì € ìˆ˜ì¹˜ë¥¼ ì¦í­ì‹œí‚µë‹ˆë‹¤.
            raw = current_realtime_prob 
            if raw <= 0.001: final_val = 0
            elif 0.001 < raw <= 0.02: final_val = 30 + (raw * 1000) 
            elif 0.02 < raw <= 0.1: final_val = 60 + (raw * 100)
            else: final_val = 85 + (raw * 10)
            prob_percent = int(min(final_val, 99))

            # 2. [ìˆ˜ì •] ì¦í­ëœ ìˆ˜ì¹˜ë¥¼ LLM í•¨ìˆ˜ì— ì¸ìë¡œ ê°™ì´ ë³´ëƒ…ë‹ˆë‹¤.
            result = await describe_heatmap(label, info, FRAME_WIDTH, calibrated_prob=prob_percent)
            
            latest_description = {
                "text": result["text"],
                "prob_percent": prob_percent, # í™”ë©´ì— í‘œì‹œë  ìˆ˜ì¹˜
                "ts": time.time(),
            }
            print(f"ğŸ”¥ [SUPER BOOST] ì›ë³¸: {raw:.4f} -> ê²°ê³¼: {prob_percent}%")
            
        except Exception as e:
            print(f"âŒ LLM Worker ì˜¤ë¥˜: {e}")

        await asyncio.sleep(0.8)

@app.on_event("startup")
async def startup_event():
    print(f"ğŸ“‚ Static ê²½ë¡œ í™•ì¸: {static_dir}")
    camera.start()
    asyncio.create_task(llm_worker())

@app.on_event("shutdown")
def shutdown_event():
    camera.stop()

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)